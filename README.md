# Computationally efficient Gauss-Newton reinforcement learning for model predictive control
This repository contains the implementation of the methods and results presented in the paper:
> **Computationally efficient Gauss-Newton reinforcement learning for model predictive control**  
> Dean Brandner, Sebastien Gros, and Sergio Lucia

## Overview
This project provides the necessary implementations for computationally efficient second-order reinforcement learning via Gauss-Newton Hessian approximations in application for model predictive control (MPC) policies.
This repository inludes:
1. An empirical validation of the superlinear convergence capability when the Gauss-Newton approximation is used in second-order reinforcement learning at the example of an analytical case study
2. Training routines of established first- and second-order reinforcement learning approaches with MPC policies for a nonlinear continuously stirred-tank reactor (CSTR) case study
3. Plotting utilitities to recreate the plots and evaluation tools to recreate results

## Repository structure
```
.
├── analytic_example/
│   └── analytic_cs.ipynb
├── CSTR/
│   ├── data/
│   │   └── results_will_appear_in_this_folder.txt
│   ├── evaluation/
│   │   └── training_time_ic_invest.py
│   ├── helper/
│   │   └── steady_state_computation.py
│   ├── plotting/
│   │   ├── learning_curves_momentum_investigation.py
│   │   ├── learning_curves_robust_ic_investigation.py
│   │   ├── parameter_plot_2d.py
│   │   └── smooth_eigenvalues_of_hessian.py
│   └── training/
│       ├── compute_parametric_performance.py
│       ├── environments.py
│       ├── helper.py
│       ├── mp_utils.py
│       ├── mpc_collection.py
│       ├── mpc_training_approx_newton.py
│       ├── mpc_training_gauss_newton.py
│       ├── mpc_training_gradient_ascent.py
│       ├── Q_func_model.py
│       ├── RL_MPC.py
│       ├── rl_mpc_agents.py
│       ├── robustness_ic_investigation_approx_newton.py
│       ├── robustness_ic_investigation_gauss_newton.py
│       └── robustness_ic_investigation_gradient_ascent.py
├── .conda.yaml
├── .gitignore
├── .LICENSE.md
└── .README.md
```

## Key components
### Analytical case study
The results of the analytical case can be reproduced by running the jupyter notebook `analytic_cs.ipynb` in the folder `analytic_example`.

### CSTR case study
All training scripts are located under `CSTR/training`. All plotting utillities can be found under `CSTR/plotting`.
The results can be obtained in the following way.

#### Averaged learning curves for robustness investigation
First run the following files:
- `robustness_ic_investigation_gradiend_ascent.py`
- `robustness_ic_investigation_gauss_newton.py`
- `robustness_ic_investigation_approx_newton.py`

Then plot the results by running `learning_curves_robust_ic_investigation.py`. Note that the data and figure path may need to be adapted.

The average computation time per iteration can be obtained by running `training_time_ic_invest.py` in `CSTR/evaluation`.

#### 2D parameter trajectory plot
First the performance for different parameter combinations must be generated for the background of the contour plot.
Run `compute_parametric_performance.py` to generate these results.

After that the training trajectories can be recorded. Run the following scripts and adapt the parameters accordingly:
- `mpc_training_gradient_ascent.py`
- `mpc_training_approx_newton.py`
- `mpc_training_gauss_newton.py`

The plot can be generated by running `parameter_plot_2d.py`. Note that the data and figure path may need to be adapted.

#### Smoothing of the Hessian
If not already previously obtained, run `mpc_training_gauss_newton.py` with the respective parameter combination.

The plot can be generated by running `smooth_eigenvalues_of_hessian.py`. Note that the data and figure path may need to be adapted.

#### Learning curves for different momentum
Enter the desired combinations of $\beta$ and $\eta$ into the respective lists in `mpc_training_gauss_newton.py` and run it.

The plot can be generated by running `learning_curves_momentum_investigation.py`. Note that the data and figure path may need to be adapted.


## Usage
### Prerequisites
Clone the repository and install the [conda](https://www.anaconda.com/docs/getting-started/miniconda/install) environment that is stored in the file `.conda.yaml`

## License
See the LICENSE.md file for license rights and limitations.
