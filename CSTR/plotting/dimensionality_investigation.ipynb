{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8456db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({\n",
    "\t\"text.usetex\": True,\n",
    "\t# \"text.usetex\": False,\n",
    "\t\"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n",
    "\t\"font.size\": 14,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29153dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "n_IC_per_replay = 200\n",
    "\n",
    "parameterizations = ['low', 'medium', 'high']\n",
    "titles = [\"Low\", \"Medium\", \"High\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6342e6c",
   "metadata": {},
   "source": [
    "## Adam with $\\alpha = 10^{-2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa2b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 1e-2\n",
    "Adam_dict = {}\n",
    "\n",
    "for parameterization in parameterizations:\n",
    "\tdata_path = os.path.join(\"..\", \"data\", \"dimensionality_investigation\", f\"gamma{gamma:.3f}, n_IC_per_replay{n_IC_per_replay}\", f\"Adam_lr_{learning_rate:.1e}\", f\"{parameterization}_parameterization\")\n",
    "\tAdam_dict[parameterization] = {\n",
    "\t\t\"data_path\": data_path,\n",
    "\t\t\"label\": r\"Adam $\\alpha=10^{-2}$\",\n",
    "\t\t\"title\": parameterization\n",
    "\t}\n",
    "\tparameters = []\n",
    "\tpolicy_gradients = []\n",
    "\t\n",
    "\tif os.path.exists(data_path):\n",
    "\t\tfolders = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f)) and not f == \"agent_update\" and not f == \"memories\" and not f == \"figs\"]\n",
    "\n",
    "\t\tfor idx in range(len(folders)):\n",
    "\t\t\tif os.path.exists(os.path.join(data_path, f\"agent_update_{idx}\", \"rl_params.pkl\")):\n",
    "\t\t\t\twith open(os.path.join(data_path, f\"agent_update_{idx}\", \"rl_params.pkl\"), \"rb\") as f:\n",
    "\t\t\t\t\trl_params = pickle.load(f)\n",
    "\t\t\t\tparameters.append(rl_params.master.full())\n",
    "\n",
    "\t\t\t\tif os.path.exists(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_gradients.pkl\")):\n",
    "\t\t\t\t\twith open(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_gradients.pkl\"), \"rb\") as f:\n",
    "\t\t\t\t\t\tpg = pickle.load(f)\n",
    "\t\t\t\t\tpolicy_gradients.append(pg)\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tnot_accessable_path = os.path.join(data_path, f\"agent_update_{idx}\", \"rl_params.pkl\")\n",
    "\t\t\t\tprint(f\"Missing rl_params.pkl in {not_accessable_path}\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tif len(parameters) == 0:\n",
    "\t\t\tprint(f\"No parameters found in {data_path}\")\n",
    "\t\t\tparameters = np.empty((0, 2, 1))\n",
    "\t\t\tpolicy_gradients = np.empty((0, 2, 1))\n",
    "\t\telse:\n",
    "\t\t\tparameters = np.stack(parameters, axis = 0)\n",
    "\t\t\tpolicy_gradients = np.stack(policy_gradients, axis = 0)\n",
    "\t\tAdam_dict[parameterization][\"parameters\"] = parameters\n",
    "\t\tAdam_dict[parameterization][\"policy_gradients\"] = policy_gradients\n",
    "\n",
    "\t\tif os.path.exists(os.path.join(data_path, \"processed_results_list.pkl\")):\n",
    "\t\t\twith open(os.path.join(data_path, \"processed_results_list.pkl\"), \"rb\") as f:\n",
    "\t\t\t\tprocessed_results_list = pickle.load(f)\n",
    "\t\t\tclc_list = [item[\"cum_reward\"][\"mean\"] for item in processed_results_list]\n",
    "\t\t\tAdam_dict[parameterization]['clc_list'] = clc_list\n",
    "\n",
    "\t\tif os.path.exists(os.path.join(data_path, \"training_time.pkl\")):\n",
    "\t\t\twith open(os.path.join(data_path, \"training_time.pkl\"), \"rb\") as f:\n",
    "\t\t\t\ttraining_time = pickle.load(f)\n",
    "\t\t\tAdam_dict[parameterization]['training_time'] = training_time\n",
    "\telse:\n",
    "\t\tprint(f\"Data path {data_path} does not exist.\")\n",
    "\t\tcontinue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9c042",
   "metadata": {},
   "source": [
    "# Load approximate Newton with trust region and $\\alpha = 10^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0601b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trust_region_radius = 1e-1\n",
    "approx_newton_tr_dict = {}\n",
    "\n",
    "for parameterization in parameterizations:\n",
    "\tdata_path = os.path.join(\"..\", \"data\", \"dimensionality_investigation\", f\"gamma{gamma:.3f}, n_IC_per_replay{n_IC_per_replay}\", f\"approx_newton_rad_{trust_region_radius:.1e}\", f\"{parameterization}_parameterization\")\n",
    "\tapprox_newton_tr_dict[parameterization] = {\n",
    "\t\t\"data_path\": data_path,\n",
    "\t\t\"label\": r\"Approx. Newton $\\alpha=10^{-1}$\"\n",
    "\t}\n",
    "\tparameters = []\n",
    "\tpolicy_gradients = []\n",
    "\tpolicy_hessians = []\n",
    "\t\n",
    "\tif os.path.exists(data_path):\n",
    "\t\tfolders = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f)) and not f == \"agent_update\" and not f == \"memories\" and not f == \"figs\"]\n",
    "\n",
    "\n",
    "\t\tfor idx in range(len(folders)):\n",
    "\t\t\tif os.path.exists(os.path.join(data_path, f\"agent_update_{idx}\", \"rl_params.pkl\")):\n",
    "\t\t\t\twith open(os.path.join(data_path, f\"agent_update_{idx}\", \"rl_params.pkl\"), \"rb\") as f:\n",
    "\t\t\t\t\trl_params = pickle.load(f)\n",
    "\t\t\t\tparameters.append(rl_params.master.full())\n",
    "\t\t\t\trl_params_not_accessable = False\n",
    "\n",
    "\t\t\t\tif os.path.exists(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_gradients.pkl\")):\n",
    "\t\t\t\t\twith open(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_gradients.pkl\"), \"rb\") as f:\n",
    "\t\t\t\t\t\tpg = pickle.load(f)\n",
    "\t\t\t\t\tpolicy_gradients.append(pg)\n",
    "\n",
    "\t\t\t\tif os.path.exists(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_hessian.pkl\")):\n",
    "\t\t\t\t\twith open(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_hessian.pkl\"), \"rb\") as f:\n",
    "\t\t\t\t\t\tph = pickle.load(f)\n",
    "\t\t\t\t\tpolicy_hessians.append(ph)\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\trl_params_not_accessable = True\n",
    "\n",
    "\t\t\tif rl_params_not_accessable:\n",
    "\t\t\t\tnot_accessable_path = os.path.join(data_path, f\"agent_update_{idx}\")\n",
    "\t\t\t\tprint(f\"Missing rl_params.pkl or revert.pkl in {not_accessable_path}\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tif len(parameters) - 1 == 0:\n",
    "\t\t\tprint(f\"No parameters found in {data_path}\")\n",
    "\t\t\tparameters = np.empty((0, 2, 1))\n",
    "\t\t\tpolicy_gradients = np.empty((0, 2, 1))\n",
    "\t\t\tpolicy_hessians = np.empty((0, 2, 2))\n",
    "\t\telse:\n",
    "\t\t\tparameters = np.stack(parameters, axis = 0)\n",
    "\t\t\tpolicy_gradients = np.stack(policy_gradients, axis = 0)\n",
    "\t\t\tpolicy_hessians = np.stack(policy_hessians, axis = 0)\n",
    "\t\t\t\n",
    "\t\tapprox_newton_tr_dict[parameterization][\"parameters\"] = parameters\n",
    "\t\tapprox_newton_tr_dict[parameterization][\"policy_gradients\"] = policy_gradients\n",
    "\t\tapprox_newton_tr_dict[parameterization][\"policy_hessians\"] = policy_hessians\n",
    "\n",
    "\t\tif os.path.exists(os.path.join(data_path, \"processed_results_list.pkl\")):\n",
    "\t\t\twith open(os.path.join(data_path, \"processed_results_list.pkl\"), \"rb\") as f:\n",
    "\t\t\t\tprocessed_results_list = pickle.load(f)\n",
    "\t\t\tclc_list = [item[\"cum_reward\"][\"mean\"] for item in processed_results_list]\n",
    "\t\t\tapprox_newton_tr_dict[parameterization]['clc_list'] = clc_list\n",
    "\t\t\tapprox_newton_tr_dict[parameterization]['clc_final'] = clc_list\n",
    "\n",
    "\t\tif os.path.exists(os.path.join(data_path, \"training_time.pkl\")):\n",
    "\t\t\twith open(os.path.join(data_path, \"training_time.pkl\"), \"rb\") as f:\n",
    "\t\t\t\ttraining_time = pickle.load(f)\n",
    "\t\t\tapprox_newton_tr_dict[parameterization]['training_time'] = training_time\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tprint(f\"Data path {data_path} does not exist.\")\n",
    "\t\tcontinue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6204c",
   "metadata": {},
   "source": [
    "# Load Gauss-Newton with trust region and $\\alpha_0 = 10^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f92c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trust_region_radius = 1e-1\n",
    "gauss_newton_tr_dict = {}\n",
    "\n",
    "for parameterization in parameterizations:\n",
    "\tdata_path = os.path.join(\"..\", \"data\", \"dimensionality_investigation\", f\"gamma{gamma:.3f}, n_IC_per_replay{n_IC_per_replay}\", f\"gauss_newton_rad_{trust_region_radius:.1e}\", f\"{parameterization}_parameterization\")\n",
    "\tgauss_newton_tr_dict[parameterization] = {\n",
    "\t\t\"data_path\": data_path,\n",
    "\t\t\"label\": r\"Gauss-Newton $\\alpha=10^{-1}$ (proposed)\"\n",
    "\t}\n",
    "\tparameters = []\n",
    "\tpolicy_gradients = []\n",
    "\tpolicy_hessians = []\n",
    "\t\n",
    "\tif os.path.exists(data_path):\n",
    "\t\tfolders = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f)) and not f == \"agent_update\" and not f == \"memories\" and not f == \"figs\"]\n",
    "\n",
    "\n",
    "\t\tfor idx in range(len(folders)):\n",
    "\t\t\tif os.path.exists(os.path.join(data_path, f\"agent_update_{idx}\", \"rl_params.pkl\")):\n",
    "\t\t\t\twith open(os.path.join(data_path, f\"agent_update_{idx}\", \"rl_params.pkl\"), \"rb\") as f:\n",
    "\t\t\t\t\trl_params = pickle.load(f)\n",
    "\t\t\t\tparameters.append(rl_params.master.full())\n",
    "\t\t\t\trl_params_not_accessable = False\n",
    "\n",
    "\t\t\t\tif os.path.exists(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_gradients.pkl\")):\n",
    "\t\t\t\t\twith open(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_gradients.pkl\"), \"rb\") as f:\n",
    "\t\t\t\t\t\tpg = pickle.load(f)\n",
    "\t\t\t\t\tpolicy_gradients.append(pg)\n",
    "\n",
    "\t\t\t\tif os.path.exists(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_hessian.pkl\")):\n",
    "\t\t\t\t\twith open(os.path.join(data_path, f\"agent_update_{idx}\", \"policy_hessian.pkl\"), \"rb\") as f:\n",
    "\t\t\t\t\t\tph = pickle.load(f)\n",
    "\t\t\t\t\tpolicy_hessians.append(ph)\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\trl_params_not_accessable = True\n",
    "\n",
    "\t\t\tif rl_params_not_accessable:\n",
    "\t\t\t\tnot_accessable_path = os.path.join(data_path, f\"agent_update_{idx}\")\n",
    "\t\t\t\tprint(f\"Missing rl_params.pkl or revert.pkl in {not_accessable_path}\")\n",
    "\n",
    "\t\tparameters = np.stack(parameters, axis = 0)\n",
    "\t\tpolicy_gradients = np.stack(policy_gradients, axis = 0)\n",
    "\t\tpolicy_hessians =  np.stack(policy_hessians, axis = 0)\n",
    "\n",
    "\t\tgauss_newton_tr_dict[parameterization][\"parameters\"] = parameters\n",
    "\t\tgauss_newton_tr_dict[parameterization][\"policy_gradients\"] = policy_gradients\n",
    "\t\tgauss_newton_tr_dict[parameterization][\"policy_hessians\"] = policy_hessians\n",
    "\n",
    "\t\t\n",
    "\t\tif os.path.exists(os.path.join(data_path, \"processed_results_list.pkl\")):\n",
    "\t\t\twith open(os.path.join(data_path, \"processed_results_list.pkl\"), \"rb\") as f:\n",
    "\t\t\t\tprocessed_results_list = pickle.load(f)\n",
    "\t\t\tclc_list = [item[\"cum_reward\"][\"mean\"] for item in processed_results_list]\n",
    "\t\t\tgauss_newton_tr_dict[parameterization]['clc_list'] = clc_list\n",
    "\t\t\tgauss_newton_tr_dict[parameterization]['clc_final'] = clc_list\n",
    "\n",
    "\t\tif os.path.exists(os.path.join(data_path, \"training_time.pkl\")):\n",
    "\t\t\twith open(os.path.join(data_path, \"training_time.pkl\"), \"rb\") as f:\n",
    "\t\t\t\ttraining_time = pickle.load(f)\n",
    "\t\t\tgauss_newton_tr_dict[parameterization]['training_time'] = training_time\n",
    "\telse:\n",
    "\t\tprint(f\"Data path {data_path} does not exist.\")\n",
    "\t\tcontinue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ce51b",
   "metadata": {},
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "figpath = os.path.join(\"..\", \"data\", \"dimensionality_investigation\", f\"gamma{gamma:.3f}, n_IC_per_replay{n_IC_per_replay}\", f\"learning_curves_scalability.png\")\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "ncols = 1\n",
    "nrows = len(parameterizations)\n",
    "\n",
    "titles = [\n",
    "\t\"Low (2)\",\n",
    "\t\"Medium (13)\",\n",
    "    \"High (33)\",\n",
    "]\n",
    "\n",
    "k = 1.0\n",
    "figsize = (k * 5 * ncols, k * 2 * nrows)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize, constrained_layout=True, sharex=True,)\n",
    "\n",
    "for axis, title in zip(ax, titles):\n",
    "\taxis.set_title(title)\n",
    "\n",
    "idx_init_step = 0\n",
    "idx_final_step = 0\n",
    "for idx, parameterization in enumerate(parameterizations):\n",
    "    if \"clc_list\" in Adam_dict[parameterization].keys():\n",
    "        indices = np.arange(len(Adam_dict[parameterization]['clc_list']))\n",
    "        if indices[-1] > idx_final_step:\n",
    "            idx_final_step = indices[-1]\n",
    "        ax[idx].plot(\n",
    "            indices,\n",
    "            Adam_dict[parameterization]['clc_list'],\n",
    "            label=Adam_dict[parameterization]['label'],\n",
    "            linestyle = '-',\n",
    "\t\t\tcolor = 'tab:blue'\n",
    "        )\n",
    "    if \"clc_final\" in approx_newton_tr_dict[parameterization].keys():\n",
    "        indices = np.arange(len(approx_newton_tr_dict[parameterization]['clc_final']))\n",
    "        if indices[-1] > idx_final_step:\n",
    "            idx_final_step = indices[-1]\n",
    "        ax[idx].plot(\n",
    "            indices,\n",
    "            approx_newton_tr_dict[parameterization]['clc_final'],\n",
    "            label=approx_newton_tr_dict[parameterization]['label'],\n",
    "            linestyle ='--',\n",
    "\t\t\tcolor = 'tab:orange'\n",
    "        )\n",
    "    if \"clc_final\" in gauss_newton_tr_dict[parameterization].keys():\n",
    "        indices = np.arange(len(gauss_newton_tr_dict[parameterization]['clc_final']))\n",
    "        if indices[-1] > idx_final_step:\n",
    "            idx_final_step = indices[-1]\n",
    "        ax[idx].plot(\n",
    "            indices,\n",
    "            gauss_newton_tr_dict[parameterization]['clc_final'],\n",
    "            label=gauss_newton_tr_dict[parameterization]['label'],\n",
    "            linestyle = ':',\n",
    "\t\t\tcolor = 'tab:green'\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "for axis in ax:\n",
    "    axis.set_ylabel(r\"$J(\\boldsymbol{\\theta})$\")\n",
    "    # axis.legend(loc = \"lower right\")\n",
    "    axis.grid(True, which = \"both\")\n",
    "\n",
    "ax[-1].set_xlabel(r\"Iteration $k$\")\n",
    "ax[-1].set_xlim([idx_init_step, idx_final_step])\n",
    "# ax[-1].set_ylim([-90, -40])\n",
    "\n",
    "ax[-1].set_xticks(np.arange(idx_init_step, idx_final_step + 1, 5.0), minor=True)\n",
    "\n",
    "# handles, labels = ax[-1].get_legend_handles_labels()\n",
    "# fig.legend(loc = \"outside lower center\", handles = handles, labels = labels)\n",
    "ax[-1].legend(loc = \"lower right\", fontsize = 12)\n",
    "\n",
    "fig.savefig(figpath, bbox_inches='tight', dpi = 300.0)\n",
    "\n",
    "figpath_pdf = figpath.replace(\".png\", \".pdf\")\n",
    "fig.savefig(figpath_pdf, bbox_inches='tight', dpi = 1200.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a62162",
   "metadata": {},
   "source": [
    "# Tabular evaluation of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_list = [\"Adam\", \"Approx. Newton\", \"Gauss-Newton\"]\n",
    "\n",
    "for method_type in methods_list:\n",
    "\tprint(f\"Method: {method_type}\")\n",
    "\n",
    "\tif method_type == \"Gauss-Newton\":\n",
    "\t\tcurrent_dict = gauss_newton_tr_dict\n",
    "\telif method_type == \"Adam\":\n",
    "\t\tcurrent_dict = Adam_dict\n",
    "\telif method_type == \"Approx. Newton\":\n",
    "\t\tcurrent_dict = approx_newton_tr_dict\n",
    "\telse:\n",
    "\t\tprint(f\"Unknown method: {method_type}\")\n",
    "\t\tcontinue\n",
    "\n",
    "\tfor parameterization_type in parameterizations:\n",
    "\t\tinitial_performance = current_dict[parameterization_type][\"clc_list\"][0]\n",
    "\t\tfinal_performance = current_dict[parameterization_type][\"clc_list\"][-1]\n",
    "\n",
    "\t\tprint(f\"Parameterization type: {parameterization_type}\")\n",
    "\t\tprint(f\"Initial performance: {initial_performance:.4f}\")\n",
    "\t\tprint(f\"Final performance: {final_performance:.4f}\")\n",
    "\t\tprint()\n",
    "\n",
    "\n",
    "\tprint()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4a376",
   "metadata": {},
   "source": [
    "# Training times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8869c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_initial_sample = True # This makes sense because the first one also includes the initialization of all subprocesses (kernel launches)\n",
    "\n",
    "lower_percentile = 10\n",
    "upper_percentile = 90\n",
    "\n",
    "for parameterization in parameterizations:\n",
    "\tprint(f\"Parameterization: {parameterization}\")\n",
    "\tif \"training_time\" in Adam_dict[parameterization].keys():\n",
    "\t\tmean_time = np.mean(Adam_dict[parameterization]['training_time'][1:] if exclude_initial_sample else Adam_dict[parameterization]['training_time'])\n",
    "\t\tstd_time = np.std(Adam_dict[parameterization]['training_time'][1:] if exclude_initial_sample else Adam_dict[parameterization]['training_time'])\n",
    "\t\tmedian_time = np.median(Adam_dict[parameterization]['training_time'][1:] if exclude_initial_sample else Adam_dict[parameterization]['training_time'])\n",
    "\t\tlower_percentile_time = np.percentile(Adam_dict[parameterization]['training_time'][1:] if exclude_initial_sample else Adam_dict[parameterization]['training_time'], lower_percentile)\n",
    "\t\tupper_percentile_time = np.percentile(Adam_dict[parameterization]['training_time'][1:] if exclude_initial_sample else Adam_dict[parameterization]['training_time'], upper_percentile)\n",
    "\n",
    "\t\tAdam_dict[parameterization]['mean_training_time'] = mean_time\n",
    "\t\tAdam_dict[parameterization]['std_training_time'] = std_time\n",
    "\t\tAdam_dict[parameterization]['median_training_time'] = median_time\n",
    "\t\tAdam_dict[parameterization]['10th_percentile_training_time'] = lower_percentile_time\n",
    "\t\tAdam_dict[parameterization]['90th_percentile_training_time'] = upper_percentile_time\n",
    "\n",
    "\t\tprint(f\"Adam Mean Training Time: {mean_time:.2f} s, Std: {std_time:.2f} s\")\n",
    "\telse:\n",
    "\t\tprint(\"No training time data for Adam.\")\n",
    "\n",
    "\tif \"training_time\" in approx_newton_tr_dict[parameterization].keys():\n",
    "\t\tmean_time = np.mean(approx_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else approx_newton_tr_dict[parameterization]['training_time'])\n",
    "\t\tstd_time = np.std(approx_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else approx_newton_tr_dict[parameterization]['training_time'])\n",
    "\t\tmedian_time = np.median(approx_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else approx_newton_tr_dict[parameterization]['training_time'])\n",
    "\t\tlower_percentile_time = np.percentile(approx_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else approx_newton_tr_dict[parameterization]['training_time'], lower_percentile)\n",
    "\t\tupper_percentile_time = np.percentile(approx_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else approx_newton_tr_dict[parameterization]['training_time'], upper_percentile)\n",
    "\n",
    "\t\tapprox_newton_tr_dict[parameterization]['mean_training_time'] = mean_time\n",
    "\t\tapprox_newton_tr_dict[parameterization]['std_training_time'] = std_time\n",
    "\t\tapprox_newton_tr_dict[parameterization]['median_training_time'] = median_time\n",
    "\t\tapprox_newton_tr_dict[parameterization]['10th_percentile_training_time'] = lower_percentile_time\n",
    "\t\tapprox_newton_tr_dict[parameterization]['90th_percentile_training_time'] = upper_percentile_time\n",
    "\n",
    "\t\tprint(f\"Approx. Newton TR Mean Training Time: {mean_time:.2f} s, Std: {std_time:.2f} s\")\n",
    "\telse:\n",
    "\t\tprint(\"No training time data for Approx. Newton TR.\")\n",
    "\n",
    "\tif \"training_time\" in gauss_newton_tr_dict[parameterization].keys():\n",
    "\t\tmean_time = np.mean(gauss_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else gauss_newton_tr_dict[parameterization]['training_time'])\n",
    "\t\tstd_time = np.std(gauss_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else gauss_newton_tr_dict[parameterization]['training_time'])\n",
    "\t\tmedian_time = np.median(gauss_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else gauss_newton_tr_dict[parameterization]['training_time'])\n",
    "\t\tlower_percentile_time = np.percentile(gauss_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else gauss_newton_tr_dict[parameterization]['training_time'], lower_percentile)\n",
    "\t\tupper_percentile_time = np.percentile(gauss_newton_tr_dict[parameterization]['training_time'][1:] if exclude_initial_sample else gauss_newton_tr_dict[parameterization]['training_time'], upper_percentile)\n",
    "\n",
    "\t\tgauss_newton_tr_dict[parameterization]['mean_training_time'] = mean_time\n",
    "\t\tgauss_newton_tr_dict[parameterization]['std_training_time'] = std_time\n",
    "\t\tgauss_newton_tr_dict[parameterization]['median_training_time'] = median_time\n",
    "\t\tgauss_newton_tr_dict[parameterization]['10th_percentile_training_time'] = lower_percentile_time\n",
    "\t\tgauss_newton_tr_dict[parameterization]['90th_percentile_training_time'] = upper_percentile_time\n",
    "\n",
    "\t\tprint(f\"Gauss-Newton TR Mean Training Time: {mean_time:.2f} s, Std: {std_time:.2f} s\")\n",
    "\telse:\n",
    "\t\tprint(\"No training time data for Gauss-Newton TR.\")\n",
    "\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figpath = os.path.join(\"..\", \"data\", \"dimensionality_investigation\", f\"gamma{gamma:.3f}, n_IC_per_replay{n_IC_per_replay}\", f\"training_times_mean_scalability.png\")\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "ncols = 1\n",
    "nrows = 1\n",
    "\n",
    "k = 0.75\n",
    "figsize = (k * 7.5 * ncols, k * 4 * nrows)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize, constrained_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "x_labels = ['Low (2)', 'Medium (13)', 'High (33)']\n",
    "\n",
    "k_sigma = 3.0\n",
    "\n",
    "results_mean = {\n",
    "\t\"Adam\": [],\n",
    "\t\"Approx. Newton\": [],\n",
    "\t\"Gauss-Newton\": [],\n",
    "}\n",
    "\n",
    "labels = [\"Adam\", \"Approx. Newton\", \"Gauss-Newton (proposed)\"]\n",
    "\n",
    "print(\"Collecting mean training times:\")\n",
    "for parameterization in parameterizations:\n",
    "\tprint(f\"Parameterization: {parameterization}\")\n",
    "\tif \"mean_training_time\" in Adam_dict[parameterization].keys():\n",
    "\t\tresults_mean[\"Adam\"].append(Adam_dict[parameterization]['mean_training_time'])\n",
    "\telse:\n",
    "\t\tresults_mean[\"Adam\"].append(0)\n",
    "\n",
    "\tif \"mean_training_time\" in approx_newton_tr_dict[parameterization].keys():\n",
    "\t\tresults_mean[\"Approx. Newton\"].append(approx_newton_tr_dict[parameterization]['mean_training_time'])\n",
    "\telse:\n",
    "\t\tresults_mean[\"Approx. Newton\"].append(0)\n",
    "\n",
    "\tif \"mean_training_time\" in gauss_newton_tr_dict[parameterization].keys():\n",
    "\t\tresults_mean[\"Gauss-Newton\"].append(gauss_newton_tr_dict[parameterization]['mean_training_time'])\n",
    "\telse:\n",
    "\t\tresults_mean[\"Gauss-Newton\"].append(0)\n",
    "\n",
    "print()\n",
    "\n",
    "results_std = {\n",
    "\t\"Adam\": [],\n",
    "\t\"Approx. Newton\": [],\n",
    "\t\"Gauss-Newton\": [],\n",
    "}\n",
    "\n",
    "print(\"Collecting std training times:\")\n",
    "for parameterization in parameterizations:\n",
    "\tprint(f\"Parameterization: {parameterization}\")\n",
    "\tif \"std_training_time\" in Adam_dict[parameterization].keys():\n",
    "\t\tresults_std[\"Adam\"].append(Adam_dict[parameterization]['std_training_time'])\n",
    "\telse:\n",
    "\t\tresults_std[\"Adam\"].append(0)\n",
    "\n",
    "\tif \"std_training_time\" in approx_newton_tr_dict[parameterization].keys():\n",
    "\t\tresults_std[\"Approx. Newton\"].append(approx_newton_tr_dict[parameterization]['std_training_time'])\n",
    "\telse:\n",
    "\t\tresults_std[\"Approx. Newton\"].append(0)\n",
    "\n",
    "\tif \"std_training_time\" in gauss_newton_tr_dict[parameterization].keys():\n",
    "\t\tresults_std[\"Gauss-Newton\"].append(gauss_newton_tr_dict[parameterization]['std_training_time'])\n",
    "\telse:\n",
    "\t\tresults_std[\"Gauss-Newton\"].append(0)\n",
    "\n",
    "\n",
    "width = 1 / (len(results_mean) + 1)\n",
    "multiplier = 0\n",
    "x = np.arange(len(x_labels))\n",
    "hatches = [\"\", \"/\", \"*\"]\n",
    "\n",
    "for hatch, label, (method, times) in zip(hatches, labels, results_mean.items()):\n",
    "\trect = ax.bar(\n",
    "\t\tx + multiplier * width,\n",
    "\t\ttimes,\n",
    "\t\twidth = width,\n",
    "\t\thatch = hatch,\n",
    "\t\tlabel=label\n",
    "\t)\n",
    "\tax.errorbar(x + multiplier * width, times, yerr=k_sigma * np.array(results_std[method]), fmt='none', ecolor='black', capsize=5)\n",
    "\tax.bar_label(rect, padding=10, fmt='%.1f', rotation=90)\n",
    "\tmultiplier += 1\n",
    "\n",
    "ax.set_ylim([0, 650])\n",
    "\n",
    "ax.legend(loc = \"upper left\", fontsize = 12)\n",
    "# fig.legend(loc = \"outside lower center\", ncols=3)\n",
    "\n",
    "ax.set_ylabel(r\"Time per RL iteration $\\left[\\mathrm{s}\\,\\mathrm{iter}^{-1}\\right]$\")\n",
    "ax.set_xticks(x + width, x_labels)\n",
    "\n",
    "fig.savefig(figpath, bbox_inches='tight', dpi = 300.0)\n",
    "\n",
    "figpath_pdf = figpath.replace(\".png\", \".pdf\")\n",
    "fig.savefig(figpath_pdf, bbox_inches='tight', dpi = 1200.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
